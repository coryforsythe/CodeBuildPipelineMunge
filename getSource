#!/usr/bin/env python
import boto3
import os
import json
from zipfile import ZipFile
import shutil

codePipelineClient = boto3.client('codepipeline')
s3Client = boto3.resource('s3')
sourcedir=os.environ['CODEBUILD_SRC_DIR']
codebuildInitiator=os.environ['CODEBUILD_INITIATOR']
print(codebuildInitiator)
codePipelineName=codebuildInitiator[13:]

print("\n\nProcessing source for "+codePipelineName+'\n\n')

pipelineData = codePipelineClient.get_pipeline(
    name=codePipelineName
)

print ("Getting artifacts from CodePipeline")
#Get artifacts
artifacts=[]
for stage in pipelineData['pipeline']['stages']:
  for action in stage['actions']:
    if action['actionTypeId']['category']=='Source':
     if 'S3Bucket' in action['configuration']:
      bucket =  action['configuration']['S3Bucket']
      object = action['configuration']['S3ObjectKey']
      uri='s3://'+bucket+'/'+object
      uriObj={}
      uriObj['bucket']=bucket
      uriObj['key']=object
      print (' -- Found S3 Source: '+uri)
      artifacts.append(uriObj)

#clean source path
print('\n\nCleaning Source Directory')
print(' -- '+sourcedir)
shutil.rmtree(sourcedir+'/*',True)

#Get source artifacts and unzip
print ('\n\nDownloading Artifacts')
for artifact in artifacts:
    file=artifact['key']
    bucket=artifact['bucket']
    print(" -- Downloading "+bucket+'/'+file)
    s3Client.meta.client.download_file(bucket,file, sourcedir+'/'+file)
    ext=os.path.splitext(file)[1]
    if (ext=='.zip'):
        print(" ---- Unzipping "+file)
        zf=ZipFile(sourcedir+'/'+file,'r')
        zf.extractall(sourcedir)
        os.remove(sourcedir+'/'+file)

#List expected artifacts
print('\n\nStructure to be packaged:');
for dirname, dirnames, filenames in os.walk(sourcedir):
    # print path to all subdirectories first.
    for subdirname in dirnames:
        print(' -- '+os.path.join(dirname, subdirname))

    # print path to all filenames.
    for filename in filenames:
        print(' -- '+os.path.join(dirname, filename))

print('\n\nDONE\n\n')
